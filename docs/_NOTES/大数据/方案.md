---
title: 银行流水实时分析系统大作业方案
date: 2025-12-26
tags: []
categories: [大数据]
---

# 银行流水实时分析系统大作业方案

## 一、项目目标

实现一个基于大数据生态的银行流水实时分析系统，支持历史数据批量导入、实时数据流处理、灵活多维查询与分析，满足高并发写入和高效查询需求。

___

## 二、技术架构

- **数据采集与传输**：Kafka
- **数据存储**：HBase（主存储）、Elasticsearch（索引与多维检索）、Hive（SQL分析）
- **数据处理**：Spark（批处理）、Spark Streaming（实时流处理）
- **数据分析**：Hive SQL、Spark SQL、Elasticsearch
- **协调与基础设施**：Zookeeper、Hadoop（HDFS、YARN）

___

## 三、系统流程与数据流

1. **历史数据导入**  
	 Spark 批处理程序读取历史数据文件，生成优化后的 rowkey，批量写入 HBase 和 Elasticsearch。

2. **实时数据处理**  
	 交易系统实时写入 Kafka，Spark Streaming 程序消费数据，生成 rowkey，实时写入 HBase 和 Elasticsearch。

3. **数据分析与查询**  
	 - Hive 外表映射 HBase，定时执行 SQL 统计分析。
	 - Elasticsearch 支持多维检索，查得 rowkey 后回查 HBase 明细。
	 - HBase Shell 支持高效前缀查询。

___

## 四、Rowkey 设计方案

### 1. 设计目标

- **唯一性**：每条流水唯一定位
- **散列性**：避免写入热点，提升并发性能
- **有序性**：支持按账号、时间等维度高效查询

### 2. 设计思路

- **rowkey = 卡号处理后 + "_" + yyyyMM + "_" + 交易流水号处理后**

#### 卡号处理方法

1. BIN号（前6位）用2位数字取代
2. 城市编号转36进制，变2位
3. 电脑顺序号转36进制，变4位
4. 校验位删除
5. 拼接后卡号倒置（逆序存储）

#### 交易流水号处理方法

- 散列加密后倒置，取后4位

#### 示例

```
rowkey = [卡号处理后]_[202501]_[流水号处理后]
```

### 3. 查询优化

- 按账号+月份查询时，使用 rowkey 前缀过滤
- 按时间范围查询时，可将时间放在 rowkey靠前位置

___

## 五、各环节操作步骤

### 1. 安装与启动

- **Zookeeper**：`zkServer.sh start`
- **HDFS**：`hdfs namenode -format`，`start-dfs.sh`
- **YARN**：`start-yarn.sh`
- **HBase**：`start-hbase.sh`
- **Hive**：`hive --service metastore &`，`hive --service hiveserver2 &`
- **Kafka**：`bin/zookeeper-server-start.sh config/zookeeper.properties`，`bin/kafka-server-start.sh config/server.properties`
- **Elasticsearch**：`./bin/elasticsearch`

### 2. HBase 建表

```shell
hbase shell
create 'transation', 'info'
```

### 3. ES 创建索引模板（可选）

```shell
curl -X PUT "localhost:9200/_index_template/transation_template" -H 'Content-Type: application/json' -d '{
	"index_patterns": ["transation-*"],
	"template": {
		"mappings": {
			"properties": {
				"account": {"type": "keyword"},
				"category": {"type": "keyword"},
				"amount": {"type": "double"},
				"date": {"type": "date"}
			}
		}
	}
}'
```

### 4. Hive 创建 HBase 外表

```sql
CREATE EXTERNAL TABLE hbase_transation(
	rowkey string,
	account string,
	category string,
	amount double,
	date string
)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,info:account,info:category,info:amount,info:date")
TBLPROPERTIES ("hbase.table.name" = "transation");
```

### 5. Spark 批处理导入历史数据

- 编写 Spark 程序，按 rowkey 规则处理后写入 HBase/ES
- 提交命令示例：

```shell
spark-submit --class com.zkpk.lab.YourBatchJob --master yarn target/your-jar-with-dependencies.jar
```

### 6. Spark Streaming 实时处理

- 编写 SparkStreaming 程序，消费 Kafka，处理 rowkey，写入 HBase/ES
- 提交命令示例：

```shell
spark-submit --class com.zkpk.lab.SparkStreamingApp --master yarn target/your-jar-with-dependencies.jar
```

### 7. HiveSQL/SparkSQL 定时分析

- HiveSQL 示例：

```sql
SELECT account, sum(amount) as total FROM hbase_transation WHERE date LIKE '2025-01%' GROUP BY account;
```

- 可用 crontab 或调度系统定时执行

---

## 六、进阶问题解答

### 1. HBase Rowkey 优化

- 采用卡号+时间+流水号散列倒置，保证唯一、散列、长度适中，避免热点

### 2. SparkStreaming 容错

- 使用 Kafka offset 管理和 Spark checkpoint，保证重启后数据不丢不重

```scala
ssc.checkpoint("hdfs://namenode:9000/spark/checkpoint")
```

___

## 七、常用查询示例

### 1. HBase Shell 查询某账号某月流水

```shell
scan 'transation', {FILTER => "PrefixFilter('卡号处理后_202501')"}
```

### 2. HBase Shell 查询某账号某月分析

- 先用 HiveSQL 分析，结果可存回 HBase 或直接查询

### 3. ES 查询+HBase 查询详情

- ES 查询：

```json
GET transation-202501/_search
{
	"query": {
		"bool": {
			"must": [
				{"term": {"account": "卡号处理后"}},
				{"term": {"category": "分类"}}
			]
		}
	}
}
```

- 拿到 rowkey 后，HBase 查询：

```shell
get 'transation', 'rowkey'
```

___

## 八、代码实现建议

- 编写工具类统一 rowkey 生成逻辑，所有入库和查询均调用
- 例：

```java
public static String buildRowKey(String cardNo, String date, String transId) {
		String cardPart = processCardNo(cardNo); // 按规则处理
		String transPart = processTransId(transId); // 散列+倒置
		return cardPart + "_" + date.substring(0,6) + "_" + transPart;
}
```

___

## 九、总结

- 方案兼顾高并发写入、灵活查询、易于扩展
- rowkey 设计科学，避免热点
- 各环节有详细操作步骤和代码建议
- 支持多种查询与分析场景

___

如需具体代码、脚本或遇到问题，欢迎随时咨询！
