---
title: 银行业务分析
date: 2025-12-28
tags: []
categories: [大数据]
---

# 银行业务分析

1. **启动hadoop集群**

   ![image-20251225161808081](/Users/dd/Library/Application Support/typora-user-images/image-20251225161808081.png)

   - **注：**环境变量的start-all.sh是spark集群的启动命令，hadoop集群启动：

     ```bash
     - cd $HADOOP_HOME/sbin
     - ./start-all.sh
     ```

   ---

2. **启动ZooKeeper集群**

   `zkServer.sh start`

![image-20251225162354042](/Users/dd/Library/Application Support/typora-user-images/image-20251225162354042.png)

![image-20251225162629993](/Users/dd/Library/Application Support/typora-user-images/image-20251225162629993.png)

---

![image-20251225162438558](/Users/dd/Library/Application Support/typora-user-images/image-20251225162438558.png)

![image-20251225162709197](/Users/dd/Library/Application Support/typora-user-images/image-20251225162709197.png)

---

![image-20251225162448509](/Users/dd/Library/Application Support/typora-user-images/image-20251225162448509.png)

![image-20251225162744802](/Users/dd/Library/Application Support/typora-user-images/image-20251225162744802.png)

---

3. **启动HBase集群**

   `start-hbase.sh`

   ![image-20251225162920104](/Users/dd/Library/Application Support/typora-user-images/image-20251225162920104.png)

   ---

4. **创建HBase表**

   ``````
   hbase shell
   
   'transitions', 'cf', {SPLITS => ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f']}
   ``````

   ![image-20251225180204845](/Users/dd/Library/Application Support/typora-user-images/image-20251225180204845.png)

   ## 表结构说明

   - 表名: transitions

   - 列族: cf (可以根据需要添加多个列族，如 info, meta 等)

   - Row Key: 使用 recid (交易流水号)，保证唯一性

   - 列:

   - cf:AccNum - 交易账号

   - cf:DealerNum - 商家账号

   - cf:DealChannle - 交易渠道

   - cf:DealTime - 处理时间戳

   - cf:DealRegion - 交易地区

   - cf:DealType - 交易类型

   - cf:MonDeal - 交易金额

   - cf:RecTime - 交易时间戳

   ---

5. **Hive创建外部表**

- 设置hive动态分区

  ``````
  SET hive.exec.dynamic.partition=true;
  SET hive.exec.dynamic.partition.mode=nonstrict;
  ``````

  ![image-20251225180711344](/Users/dd/Library/Application Support/typora-user-images/image-20251225180711344.png)

- 创建外部表

  ``````
  -- 创建Hive外表关联HBase表
  CREATE EXTERNAL TABLE transactions_hive(
    recid        STRING COMMENT 'Transaction serial number',
    accNum       STRING COMMENT 'Transaction account number',
    dealerNum    STRING COMMENT 'Merchant account number',
    dealChannel  STRING COMMENT 'Transaction channel',  -- 修正原拼写错误 dealChannle → dealChannel
    dealTime     BIGINT COMMENT 'Processing timestamp',
    dealRegion   STRING COMMENT 'Transaction region',
    dealType     STRING COMMENT 'Transaction type',
    monDeal      STRING COMMENT 'Transaction amount',
    recTime      BIGINT COMMENT 'Transaction timestamp'
  )
  STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
  WITH SERDEPROPERTIES (
    "hbase.columns.mapping" =
    ":key,cf:AccNum,cf:DealerNum,cf:DealChannle,cf:DealTime#b,cf:DealRegion,cf:DealType,cf:MonDeal,cf:RecTime#b"
  )
  TBLPROPERTIES (
    "hbase.table.name" = "transitions",
    "hbase.mapred.output.outputtable" = "transitions",
    "hbase.table.default.storage.type" = "binary"
  );
  ``````
  
  ![image-20251227152226685](/Users/dd/Library/Application Support/typora-user-images/image-20251227152226685.png)

### 列映射关系

- :key - 对应HBase的Row Key（交易流水号 recid）

- cf:AccNum - 交易账号

- cf:DealerNum - 商家账号

- cf:DealChannle - 交易渠道

- cf:DealTime - 处理时间戳

- cf:DealRegion - 交易地区

- cf:DealType - 交易类型

- cf:MonDeal - 交易金额

- cf:RecTime - 交易时间戳

---

6. **启动kafka集群(按顺序执行)**

​	`./kafka_2.11-0.10.2.1/bin/kafka-server-start.sh -daemon ./kafka_2.11-0.10.2.1/config/server.properties`

​	![image-20251225195859033](/Users/dd/Library/Application Support/typora-user-images/image-20251225195859033.png)

---

7. **创建kafka主题**

``````
./kafka_2.11-0.10.2.1/bin/kafka-topics.sh --create \
  --zookeeper master:2181 \
  --topic example \
  --partitions 3 \
  --replication-factor 1
``````

---

8. **maven打包**

   ![image-20251226142221503](/Users/dd/Library/Application Support/typora-user-images/image-20251226142221503.png)

   ---

9. **准备核验**

   - Kafka 主题：
     ``````
     ./kafka_2.11-0.10.2.1/bin/kafka-topics.sh --list --zookeeper master:2181
     ./kafka_2.11-0.10.2.1/bin/kafka-topics.sh --describe --topic example --zookeeper master:2181
     ``````

   ![image-20251227114449942](/Users/dd/Library/Application Support/typora-user-images/image-20251227114449942.png)

   - HBase 表：

     ``````
     hbase shell <<'EOF'
     list
     describe 'transitions'
     EOF
     ``````

     ![image-20251227114516678](/Users/dd/Library/Application Support/typora-user-images/image-20251227114516678.png)

---

10. **运行消费者**

    ``````
    spark-submit \
      --class com.zkpk.lab.SparkStreamingApp \
      --master local[2] \
      /home/zkpk/bankwork/sparkStreaming/target/sparkStreaming-1.0-SNAPSHOT.jar
    ``````

    

    ![image-20251227115224796](/Users/dd/Library/Application Support/typora-user-images/image-20251227115224796.png)

---

11. **运行生产者**

    ``````
    java -cp /home/zkpk/bankwork/sparkStreaming/target/sparkStreaming-1.0-SNAPSHOT.jar \
      com.zkpk.lab.KafkaProducerApp
    ``````

    ![image-20251227115354909](/Users/dd/Library/Application Support/typora-user-images/image-20251227115354909.png)

    ![image-20251227120559538](/Users/dd/Library/Application Support/typora-user-images/image-20251227120559538.png)

---

12. **快速验证**

``````
hbase shell

get 'transitions', '1e69ad20dc384a299cb8c160661d0bc1'
``````

![image-20251227154349294](/Users/dd/Library/Application Support/typora-user-images/image-20251227154349294.png)

``````
hive

SELECT *
FROM transactions_hive
WHERE recid = '1e69ad20dc384a299cb8c160661d0bc1';
``````

![image-20251227154420258](/Users/dd/Library/Application Support/typora-user-images/image-20251227154420258.png)

---

# 大作业内容

1. Hbase在shell命令窗口利用scan命令快速查询某账号2010-01-01 的交易流水

``````
# hbase shell
acc      = "512425055619695"            # 数据源的第一条数据账户
start_ts = 1262275200000        # 2010-01-01 00:00:00
end_ts   = 1262361600000        # 2010-01-02 00:00:00

Bytes = org.apache.hadoop.hbase.util.Bytes

scan 'transitions',
     { COLUMNS => ['cf:AccNum','cf:RecTime','cf:MonDeal','cf:DealType'],
       FILTER  => "SingleColumnValueFilter('cf','AccNum',=,'binary:#{acc}')" } do |row, cells|
  rec_time = Bytes.toLong(cells['cf:RecTime'].value)
  next unless rec_time >= start_ts && rec_time < end_ts
  deal_type = Bytes.toString(cells['cf:DealType'].value)
  mon_deal  = Bytes.toString(cells['cf:MonDeal'].value)
  puts "#{row}\t#{rec_time}\t#{deal_type}\t#{mon_deal}"
end
``````

![image-20251227155446022](/Users/dd/Library/Application Support/typora-user-images/image-20251227155446022.png)

2. Hbaseshell命令窗口利用scan命令快速查询某账号2010-01-01 的交易分析

``````
# hbase shell
acc      = "512425055619695"            # 数据源的第一条数据账户
start_ts = 1262275200000
end_ts   = 1262361600000

Bytes = org.apache.hadoop.hbase.util.Bytes

stats = Hash.new { |h,k| h[k] = {cnt: 0, amt: 0.0} }
total = {cnt: 0, amt: 0.0}

scan 'transitions',
     { COLUMNS => ['cf:AccNum','cf:RecTime','cf:MonDeal','cf:DealType'],
       FILTER  => "SingleColumnValueFilter('cf','AccNum',=,'binary:#{acc}')" } do |row, cells|
  rec_time = Bytes.toLong(cells['cf:RecTime'].value)
  next unless rec_time >= start_ts && rec_time < end_ts
  amt  = Bytes.toString(cells['cf:MonDeal'].value).to_f
  type = Bytes.toString(cells['cf:DealType'].value)

  stats[type][:cnt] += 1
  stats[type][:amt] += amt
  total[:cnt]       += 1
  total[:amt]       += amt
end

puts "TOTAL\t#{total[:cnt]} tx\t#{total[:amt]}"
stats.each do |type, v|
  puts "#{type}\t#{v[:cnt]} tx\t#{v[:amt]}"
end
``````





**注**：如果RegionServer挂了，需要在两个从节点重启RS

``````
/home/zkpk/hbase-1.2.6/bin/hbase-daemon.sh stop regionserver
/home/zkpk/hbase-1.2.6/bin/hbase-daemon.sh start regionserver
``````

